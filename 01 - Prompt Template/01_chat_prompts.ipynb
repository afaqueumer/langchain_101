{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1614b054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760205708.748931 2401397 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0259ef",
   "metadata": {},
   "source": [
    "## Messages in Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c92a59",
   "metadata": {},
   "source": [
    "### Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1d380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1e6083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='4 is greater than 2.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--9949ecea-63b3-41b6-95fb-463857069dbb-0', usage_metadata={'input_tokens': 15, 'output_tokens': 7, 'total_tokens': 22, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "    SystemMessage(content='You are a helpful assistant'),\n",
    "    HumanMessage(content='Which is greater 2 or 4?')\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a601e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Which is greater 2 or 4?', additional_kwargs={}, response_metadata={}), AIMessage(content='4 is greater than 2.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "messages.append(AIMessage(content=result.content))\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26580300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba81f20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a helpful assistant' additional_kwargs={} response_metadata={}\n",
      "content='Which is greater 2 or 4?' additional_kwargs={} response_metadata={}\n",
      "content='4 is greater than 2.' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "for i in messages:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59f650fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemMessage: content='You are a helpful assistant' additional_kwargs={} response_metadata={}\n",
      "HumanMessage: content='Which is greater 2 or 4?' additional_kwargs={} response_metadata={}\n",
      "AIMessage: content='4 is greater than 2.' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "    print(f\"{msg.__class__.__name__}: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5664fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input('You: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6564001",
   "metadata": {},
   "source": [
    "##### Using Static concept to iterate as chatbot - [Creating conversational context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59a1b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  **4 is higher than 2.**\n",
      "AI:  To tell you what is higher, I need to know what you're comparing!\n",
      "\n",
      "Please give me two or more things to compare, and I'll tell you which one is higher.\n",
      "AI:  You previously asked me to compare **2** and **4**.\n",
      "AI:  Okay, the higher number from our previous comparison was 4.\n",
      "\n",
      "Multiplying the higher number (4) by 5 gives us:\n",
      "\n",
      "4 * 5 = **20**\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(content='You are a helpful AI assistant')\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = llm.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(\"AI: \",result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4042df01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3e4882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a helpful AI assistant' additional_kwargs={} response_metadata={}\n",
      "content='what is higher 2 or 4?' additional_kwargs={} response_metadata={}\n",
      "content='**4 is higher than 2.**' additional_kwargs={} response_metadata={}\n",
      "content='what is higher?' additional_kwargs={} response_metadata={}\n",
      "content=\"To tell you what is higher, I need to know what you're comparing!\\n\\nPlease give me two or more things to compare, and I'll tell you which one is higher.\" additional_kwargs={} response_metadata={}\n",
      "content='what i asked previously to compare?' additional_kwargs={} response_metadata={}\n",
      "content='You previously asked me to compare **2** and **4**.' additional_kwargs={} response_metadata={}\n",
      "content='yes so multiply the higher number by 5' additional_kwargs={} response_metadata={}\n",
      "content='Okay, the higher number from our previous comparison was 4.\\n\\nMultiplying the higher number (4) by 5 gives us:\\n\\n4 * 5 = **20**' additional_kwargs={} response_metadata={}\n",
      "content='exit' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "for i in chat_history:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80499b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemMessage: content='You are a helpful AI assistant' additional_kwargs={} response_metadata={}\n",
      "HumanMessage: content='what is higher 2 or 4?' additional_kwargs={} response_metadata={}\n",
      "AIMessage: content='**4 is higher than 2.**' additional_kwargs={} response_metadata={}\n",
      "HumanMessage: content='what is higher?' additional_kwargs={} response_metadata={}\n",
      "AIMessage: content=\"To tell you what is higher, I need to know what you're comparing!\\n\\nPlease give me two or more things to compare, and I'll tell you which one is higher.\" additional_kwargs={} response_metadata={}\n",
      "HumanMessage: content='what i asked previously to compare?' additional_kwargs={} response_metadata={}\n",
      "AIMessage: content='You previously asked me to compare **2** and **4**.' additional_kwargs={} response_metadata={}\n",
      "HumanMessage: content='yes so multiply the higher number by 5' additional_kwargs={} response_metadata={}\n",
      "AIMessage: content='Okay, the higher number from our previous comparison was 4.\\n\\nMultiplying the higher number (4) by 5 gives us:\\n\\n4 * 5 = **20**' additional_kwargs={} response_metadata={}\n",
      "HumanMessage: content='exit' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "for msg in chat_history:\n",
    "    print(f\"{msg.__class__.__name__}: {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed6023",
   "metadata": {},
   "source": [
    "### Dynamic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "457e0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful cricket expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain in simple terms, what is Dusra', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful {domain} expert'),\n",
    "    ('human', 'Explain in simple terms, what is {topic}')\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({'domain':'cricket','topic':'Dusra'})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545d5b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompt_values.ChatPromptValue"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7688b34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Imagine a bowler who spins the ball. Usually, when a spinner bowls, the ball spins away from the batsman.\\n\\nNow, imagine a bowler who can do something a bit different. When they bowl, the ball spins **towards** the batsman instead of away from them. This is called the **Doosra**.\\n\\nThink of it like this:\\n\\n*   **Normal spin:** The ball turns **away** from the batsman.\\n*   **Doosra:** The ball turns **into** the batsman.\\n\\nIt's a trick ball that can be very difficult for batsmen to read and play because it goes the opposite way to what they might expect from that type of bowler.\\n\\n**In simple terms, the Doosra is a special type of spin delivery that turns in the opposite direction to a standard off-spin delivery.**\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--0cbc932c-059d-4815-b4db-62d01c76e1d0-0', usage_metadata={'input_tokens': 16, 'output_tokens': 171, 'total_tokens': 187, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682d822",
   "metadata": {},
   "source": [
    "#### Message Place holder: this is what allows you to inject a dynamic list of previous messages into your chat template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59c5f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful mathematics teacher', additional_kwargs={}, response_metadata={}), HumanMessage(content='Which is greater among 25 and 45?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# chat template\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system','You are a helpful mathematics teacher'),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human','{query}')\n",
    "])\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "query = \"Which is greater among 25 and 45?\"\n",
    "\n",
    "# create prompt\n",
    "prompt = chat_template.invoke({'chat_history':chat_history, 'query': query})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09b667a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The number **45** is greater than 25.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--57333c2f-4f9d-469a-9050-6c81ca45a8cb-0', usage_metadata={'input_tokens': 19, 'output_tokens': 13, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e2511a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append to history\n",
    "chat_history.append(HumanMessage(content=query))\n",
    "chat_history.append(AIMessage(content=response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ce8a7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Which is greater among 25 and 45?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The number **45** is greater than 25.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c0ed6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful mathematics teacher', additional_kwargs={}, response_metadata={}), HumanMessage(content='Which is greater among 25 and 45?', additional_kwargs={}, response_metadata={}), AIMessage(content='The number **45** is greater than 25.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Add 10 to the lowest number of the above two', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "query_1 = \"Add 10 to the lowest number of the above two\"\n",
    "\n",
    "# Update prompt\n",
    "prompt = chat_template.invoke({'chat_history':chat_history, 'query': query_1})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81232b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The lowest number of the two (25 and 45) is 25.\\n\\nAdding 10 to 25 gives us:\\n\\n25 + 10 = **35**', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': []}, id='run--8c91aa6d-fb03-42bf-ace7-38980d1cad62-0', usage_metadata={'input_tokens': 46, 'output_tokens': 43, 'total_tokens': 89, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b2038fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append(HumanMessage(content=query_1))\n",
    "chat_history.append(AIMessage(content=response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b53e41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Which is greater among 25 and 45?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The number **45** is greater than 25.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Add 10 to the lowest number of the above two', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='The lowest number of the two (25 and 45) is 25.\\n\\nAdding 10 to 25 gives us:\\n\\n25 + 10 = **35**', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f793424",
   "metadata": {},
   "source": [
    "##### Dynamic tempalte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e2665c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful cricket expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain in simple terms, what is Dusra', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful {domain} expert'),\n",
    "    ('human', 'Explain in simple terms, what is {topic}')\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({'domain':'cricket','topic':'Dusra'})\n",
    "\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
